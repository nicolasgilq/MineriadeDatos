{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 9\n",
    "\n",
    "## Mashable news stories analysis\n",
    "\n",
    "Predicting if a news story is going to be popular\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>timedelta</th>\n",
       "      <th>n_tokens_title</th>\n",
       "      <th>n_tokens_content</th>\n",
       "      <th>n_unique_tokens</th>\n",
       "      <th>n_non_stop_words</th>\n",
       "      <th>n_non_stop_unique_tokens</th>\n",
       "      <th>num_hrefs</th>\n",
       "      <th>num_self_hrefs</th>\n",
       "      <th>num_imgs</th>\n",
       "      <th>...</th>\n",
       "      <th>min_positive_polarity</th>\n",
       "      <th>max_positive_polarity</th>\n",
       "      <th>avg_negative_polarity</th>\n",
       "      <th>min_negative_polarity</th>\n",
       "      <th>max_negative_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <th>abs_title_subjectivity</th>\n",
       "      <th>abs_title_sentiment_polarity</th>\n",
       "      <th>Popular</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://mashable.com/2014/12/10/cia-torture-rep...</td>\n",
       "      <td>28.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>0.732620</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.844262</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.80</td>\n",
       "      <td>-0.487500</td>\n",
       "      <td>-0.60</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://mashable.com/2013/10/18/bitlock-kicksta...</td>\n",
       "      <td>447.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>0.653199</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>-0.135340</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://mashable.com/2013/07/24/google-glass-po...</td>\n",
       "      <td>533.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.660377</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.775701</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://mashable.com/2013/11/21/these-are-the-m...</td>\n",
       "      <td>413.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>781.0</td>\n",
       "      <td>0.497409</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.677350</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.195701</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>-0.071429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://mashable.com/2014/02/11/parking-ticket-...</td>\n",
       "      <td>331.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.830357</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.55</td>\n",
       "      <td>-0.175000</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  timedelta  \\\n",
       "0  http://mashable.com/2014/12/10/cia-torture-rep...       28.0   \n",
       "1  http://mashable.com/2013/10/18/bitlock-kicksta...      447.0   \n",
       "2  http://mashable.com/2013/07/24/google-glass-po...      533.0   \n",
       "3  http://mashable.com/2013/11/21/these-are-the-m...      413.0   \n",
       "4  http://mashable.com/2014/02/11/parking-ticket-...      331.0   \n",
       "\n",
       "   n_tokens_title  n_tokens_content  n_unique_tokens  n_non_stop_words  \\\n",
       "0             9.0             188.0         0.732620               1.0   \n",
       "1             7.0             297.0         0.653199               1.0   \n",
       "2            11.0             181.0         0.660377               1.0   \n",
       "3            12.0             781.0         0.497409               1.0   \n",
       "4             8.0             177.0         0.685714               1.0   \n",
       "\n",
       "   n_non_stop_unique_tokens  num_hrefs  num_self_hrefs  num_imgs   ...     \\\n",
       "0                  0.844262        5.0             1.0       1.0   ...      \n",
       "1                  0.815789        9.0             4.0       1.0   ...      \n",
       "2                  0.775701        4.0             3.0       1.0   ...      \n",
       "3                  0.677350       10.0             3.0       1.0   ...      \n",
       "4                  0.830357        3.0             2.0       1.0   ...      \n",
       "\n",
       "   min_positive_polarity  max_positive_polarity  avg_negative_polarity  \\\n",
       "0               0.200000                   0.80              -0.487500   \n",
       "1               0.160000                   0.50              -0.135340   \n",
       "2               0.136364                   1.00               0.000000   \n",
       "3               0.100000                   1.00              -0.195701   \n",
       "4               0.100000                   0.55              -0.175000   \n",
       "\n",
       "   min_negative_polarity  max_negative_polarity  title_subjectivity  \\\n",
       "0                  -0.60              -0.250000                 0.9   \n",
       "1                  -0.40              -0.050000                 0.1   \n",
       "2                   0.00               0.000000                 0.3   \n",
       "3                  -0.40              -0.071429                 0.0   \n",
       "4                  -0.25              -0.100000                 0.0   \n",
       "\n",
       "   title_sentiment_polarity  abs_title_subjectivity  \\\n",
       "0                       0.8                     0.4   \n",
       "1                      -0.1                     0.4   \n",
       "2                       1.0                     0.2   \n",
       "3                       0.0                     0.5   \n",
       "4                       0.0                     0.5   \n",
       "\n",
       "   abs_title_sentiment_polarity  Popular  \n",
       "0                           0.8        1  \n",
       "1                           0.1        0  \n",
       "2                           1.0        0  \n",
       "3                           0.0        0  \n",
       "4                           0.0        0  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/albahnsen/PracticalMachineLearningClass/master/datasets/mashable.csv'\n",
    "train_df = pd.read_csv(url, index_col=0)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000, 61)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df.drop(['url', 'Popular'], axis=1)\n",
    "y = train_df['Popular']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 9.1\n",
    "\n",
    "Estimate a Decision Tree Classifier and a Logistic Regresion\n",
    "\n",
    "Evaluate using the following metrics:\n",
    "* Accuracy\n",
    "* F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tree classifier\n",
    "treeclf = DecisionTreeClassifier(max_depth=None, random_state=1)\n",
    "treeclf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exercise 9.1 - a\n",
      "\n",
      "Accuracy: \n",
      " 0.5426666666666666\n",
      "f1_Score: \n",
      " 0.5402144772117962\n",
      "Confusion Matrix: \n",
      " [[411 333]\n",
      " [353 403]]\n"
     ]
    }
   ],
   "source": [
    "print('\\nExercise 9.1 - a\\n')\n",
    "Y_1a_predictions = treeclf.predict(X_test)\n",
    "print('Accuracy: \\n', accuracy_score(y_test, Y_1a_predictions))\n",
    "print('f1_Score: \\n', f1_score(y_test, Y_1a_predictions))\n",
    "print('Confusion Matrix: \\n', confusion_matrix(y_test, Y_1a_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1000000000.0, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reglogic = LogisticRegression(solver='liblinear', C=1e9)\n",
    "reglogic.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exercise 9.1 - b\n",
      "\n",
      "Accuracy: \n",
      " 0.6213333333333333\n",
      "f1_Score: \n",
      " 0.6033519553072626\n",
      "Confusion Matrix: \n",
      " [[500 244]\n",
      " [324 432]]\n"
     ]
    }
   ],
   "source": [
    "print('\\nExercise 9.1 - b\\n')\n",
    "Y_1b_predictions = reglogic.predict(X_test)\n",
    "print('Accuracy: \\n', accuracy_score(y_test, Y_1b_predictions))\n",
    "print('f1_Score: \\n', f1_score(y_test, Y_1b_predictions))\n",
    "print('Confusion Matrix: \\n', confusion_matrix(y_test, Y_1b_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando revisamos los resultados anteriores de los dos modelos, el mejor ajuste se realiza con la regresion logistica, ya que dan mejores metricas el Accuracy y el f1_score. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 9.2\n",
    "\n",
    "Estimate 300 bagged samples\n",
    "\n",
    "Estimate the following set of classifiers:\n",
    "\n",
    "* 100 Decision Trees where max_depth=None\n",
    "* 100 Decision Trees where max_depth=2\n",
    "* 100 Logistic Regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MLNDGIL\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
       "            splitter='best'),\n",
       "         bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
       "         max_samples=1.0, n_estimators=100, n_jobs=-1, oob_score=True,\n",
       "         random_state=1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treeclf2a = DecisionTreeClassifier(max_depth=None, random_state=1)\n",
    "clf2a = BaggingClassifier(base_estimator=treeclf2a, n_estimators=100, bootstrap=True,\n",
    "                       random_state=1, n_jobs=-1, oob_score=True)\n",
    "clf2a.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
       "            splitter='best'),\n",
       "         bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
       "         max_samples=1.0, n_estimators=100, n_jobs=-1, oob_score=True,\n",
       "         random_state=1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treeclf3a = DecisionTreeClassifier(max_depth=2, random_state=1)\n",
    "clf3a = BaggingClassifier(base_estimator=treeclf3a, n_estimators=100, bootstrap=True,\n",
    "                       random_state=1, n_jobs=-1, oob_score=True)\n",
    "clf3a.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=LogisticRegression(C=1000000000.0, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False),\n",
       "         bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
       "         max_samples=1.0, n_estimators=100, n_jobs=-1, oob_score=True,\n",
       "         random_state=1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reglogic1 = LogisticRegression(solver='liblinear', C=1e9)\n",
    "logic1 = BaggingClassifier(base_estimator=reglogic1, n_estimators=100, bootstrap=True,\n",
    "                       random_state=1, n_jobs=-1, oob_score=True)\n",
    "logic1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 9.3\n",
    "\n",
    "Ensemble using majority voting\n",
    "\n",
    "Evaluate using the following metrics:\n",
    "* Accuracy\n",
    "* F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exercise 9.3 - a\n",
      "\n",
      "Accuracy: \n",
      " 0.6386666666666667\n",
      "f1_Score: \n",
      " 0.635752688172043\n"
     ]
    }
   ],
   "source": [
    "print('\\nExercise 9.3 - a\\n')\n",
    "y3a_pred = clf2a.predict(X_test)\n",
    "print('Accuracy: \\n', accuracy_score(y_test, y3a_pred))\n",
    "print('f1_Score: \\n', f1_score(y_test, y3a_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exercise 9.3 - b\n",
      "\n",
      "Accuracy: \n",
      " 0.6446666666666667\n",
      "f1_Score: \n",
      " 0.6434782608695653\n"
     ]
    }
   ],
   "source": [
    "print('\\nExercise 9.3 - b\\n')\n",
    "y3b_pred = clf3a.predict(X_test)\n",
    "print('Accuracy: \\n', accuracy_score(y_test, y3b_pred))\n",
    "print('f1_Score: \\n', f1_score(y_test, y3b_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exercise 9.3 - c\n",
      "\n",
      "Accuracy: \n",
      " 0.626\n",
      "f1_Score: \n",
      " 0.6085136078157711\n"
     ]
    }
   ],
   "source": [
    "print('\\nExercise 9.3 - c\\n')\n",
    "y3c_pred = logic1.predict(X_test)\n",
    "print('Accuracy: \\n', accuracy_score(y_test, y3c_pred))\n",
    "print('f1_Score: \\n', f1_score(y_test, y3c_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando se evaluan los resultados de los modelos, nos damos cuenta que el 100 Decision Trees where max_depth=2, da el mejor ajuste al modelo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 9.4\n",
    "\n",
    "Estimate te probability as %models that predict positive\n",
    "\n",
    "Modify the probability threshold and select the one that maximizes the F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.488"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Declaro varibales\n",
    "y_pred_4a = y3a_pred.sum() / len(y3a_pred)\n",
    "y_pred_4a "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La probabilidadpostiva del modelo es de 48,8%. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 9.5\n",
    "\n",
    "Ensemble using weighted voting using the oob_error\n",
    "\n",
    "Evaluate using the following metrics:\n",
    "* Accuracy\n",
    "* F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exercise 9.5 - a\n",
      "\n",
      "Accuracy: \n",
      " 0.6373333333333333\n",
      "f1_Score: \n",
      " 0.6378162450066578\n"
     ]
    }
   ],
   "source": [
    "errors = np.zeros(clf2a.n_estimators)\n",
    "y_pred_all_ = np.zeros((X_test.shape[0], clf2a.n_estimators))\n",
    "\n",
    "for i in range(clf2a.n_estimators):\n",
    "   oob_sample = ~clf2a.estimators_samples_[i]\n",
    "   y_pred_ = clf2a.estimators_[i].predict(X_train.values[oob_sample])\n",
    "   errors[i] = accuracy_score(y_pred_, y_train.values[oob_sample])\n",
    "   y_pred_all_[:, i] = clf2a.estimators_[i].predict(X_test)\n",
    "\n",
    "alpha_a = (1 - errors) / (1 - errors).sum()\n",
    "\n",
    "print('\\nExercise 9.5 - a\\n')\n",
    "y5a_pred = (np.sum(y_pred_all_ * alpha_a, axis=1) >= 0.5).astype(np.int)\n",
    "print('Accuracy: \\n', accuracy_score(y_test, y5a_pred))\n",
    "print('f1_Score: \\n', f1_score(y_test, y5a_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exercise 9.5 - b\n",
      "\n",
      "Accuracy: \n",
      " 0.6446666666666667\n",
      "f1_Score: \n",
      " 0.6439545758183033\n"
     ]
    }
   ],
   "source": [
    "errors1 = np.zeros(clf3a.n_estimators)\n",
    "y_pred_all_1 = np.zeros((X_test.shape[0], clf3a.n_estimators))\n",
    "\n",
    "for i in range(clf3a.n_estimators):\n",
    "   oob_sample1 = ~clf3a.estimators_samples_[i]\n",
    "   y_pred_1 = clf3a.estimators_[i].predict(X_train.values[oob_sample])\n",
    "   errors1[i] = accuracy_score(y_pred_1, y_train.values[oob_sample])\n",
    "   y_pred_all_1[:, i] = clf3a.estimators_[i].predict(X_test)\n",
    "\n",
    "alpha_b = (1 - errors) / (1 - errors).sum()\n",
    "\n",
    "print('\\nExercise 9.5 - b\\n')\n",
    "y5b_pred = (np.sum(y_pred_all_1 * alpha_a, axis=1) >= 0.5).astype(np.int)\n",
    "print('Accuracy: \\n', accuracy_score(y_test, y5b_pred))\n",
    "print('f1_Score: \\n', f1_score(y_test, y5b_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exercise 9.5 - c\n",
      "\n",
      "Accuracy: \n",
      " 0.628\n",
      "f1_Score: \n",
      " 0.6103351955307262\n"
     ]
    }
   ],
   "source": [
    "errors2 = np.zeros(logic1.n_estimators)\n",
    "y_pred_all_2 = np.zeros((X_test.shape[0], clf3a.n_estimators))\n",
    "\n",
    "for i in range(logic1.n_estimators):\n",
    "   oob_sample2 = ~logic1.estimators_samples_[i]\n",
    "   y_pred_2 = logic1.estimators_[i].predict(X_train.values[oob_sample])\n",
    "   errors2[i] = accuracy_score(y_pred_2, y_train.values[oob_sample])\n",
    "   y_pred_all_2[:, i] = logic1.estimators_[i].predict(X_test)\n",
    "\n",
    "alpha_c = (1 - errors) / (1 - errors).sum()\n",
    "\n",
    "print('\\nExercise 9.5 - c\\n')\n",
    "y5c_pred = (np.sum(y_pred_all_2 * alpha_a, axis=1) >= 0.5).astype(np.int)\n",
    "print('Accuracy: \\n', accuracy_score(y_test, y5c_pred))\n",
    "print('f1_Score: \\n', f1_score(y_test, y5c_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando evaluamos los modelos de los anteriores items usando the oob_error, encontramos que el modelo que mas se ajusta es el de 100 Decision Trees where max_depth=2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 9.6\n",
    "\n",
    "Estimate te probability of the weighted voting\n",
    "\n",
    "Modify the probability threshold and select the one that maximizes the F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exercise 9.6_1 - a\n",
      "\n",
      "Accuracy: \n",
      " 0.514\n",
      "f1_Score: \n",
      " 0.6741171211443898\n"
     ]
    }
   ],
   "source": [
    "# 100 Decision Trees where max_depth=None\n",
    "\n",
    "# Threshold = 0.1\n",
    "print('\\nExercise 9.6_1 - a\\n')\n",
    "y6a_pred_1 = (np.sum(y_pred_all_ * alpha_a, axis=1) >= 0.1).astype(np.int)\n",
    "print('Accuracy: \\n', accuracy_score(y_test, y6a_pred_1))\n",
    "print('f1_Score: \\n', f1_score(y_test, y6a_pred_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exercise 9.6_2 - a\n",
      "\n",
      "Accuracy: \n",
      " 0.5906666666666667\n",
      "f1_Score: \n",
      " 0.6981317600786627\n"
     ]
    }
   ],
   "source": [
    "# Threshold = 0.3\n",
    "print('\\nExercise 9.6_2 - a\\n')\n",
    "y6a_pred_2 = (np.sum(y_pred_all_ * alpha_a, axis=1) >= 0.3).astype(np.int)\n",
    "print('Accuracy: \\n', accuracy_score(y_test, y6a_pred_2))\n",
    "print('f1_Score: \\n', f1_score(y_test, y6a_pred_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exercise 9.6_3 - a\n",
      "\n",
      "Accuracy: \n",
      " 0.5706666666666667\n",
      "f1_Score: \n",
      " 0.33471074380165283\n"
     ]
    }
   ],
   "source": [
    "# Threshold = 0.7\n",
    "print('\\nExercise 9.6_3 - a\\n')\n",
    "y6a_pred_3 = (np.sum(y_pred_all_ * alpha_a, axis=1) >= 0.7).astype(np.int)\n",
    "print('Accuracy: \\n', accuracy_score(y_test, y6a_pred_3))\n",
    "print('f1_Score: \\n', f1_score(y_test, y6a_pred_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exercise 9.6_4 - a\n",
      "\n",
      "Accuracy: \n",
      " 0.49866666666666665\n",
      "f1_Score: \n",
      " 0.015706806282722512\n"
     ]
    }
   ],
   "source": [
    "# Threshold = 0.9\n",
    "print('\\nExercise 9.6_4 - a\\n')\n",
    "y6a_pred_4 = (np.sum(y_pred_all_ * alpha_a, axis=1) >= 0.9).astype(np.int)\n",
    "print('Accuracy: \\n', accuracy_score(y_test, y6a_pred_4))\n",
    "print('f1_Score: \\n', f1_score(y_test, y6a_pred_4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este ejercicio, el que mas se ajusta al modelo de acuerdo al f1_score es cuando utilizamos Threshold = 0.3; arrojando una probabilidad del 70%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exercise 9.6_2 - b\n",
      "\n",
      "Accuracy: \n",
      " 0.6406666666666667\n",
      "f1_Score: \n",
      " 0.6524822695035462\n"
     ]
    }
   ],
   "source": [
    "# 100 Decision Trees where max_depth=2\n",
    "\n",
    "# Threshold = 0.1\n",
    "print('\\nExercise 9.6_2 - b\\n')\n",
    "y6b_pred_1 = (np.sum(y_pred_all_1 * alpha_a, axis=1) >= 0.1).astype(np.int)\n",
    "print('Accuracy: \\n', accuracy_score(y_test, y6b_pred_1))\n",
    "print('f1_Score: \\n', f1_score(y_test, y6b_pred_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exercise 9.6_2 - b\n",
      "\n",
      "Accuracy: \n",
      " 0.6453333333333333\n",
      "f1_Score: \n",
      " 0.6453333333333333\n"
     ]
    }
   ],
   "source": [
    "# Threshold = 0.3\n",
    "print('\\nExercise 9.6_2 - b\\n')\n",
    "y6b_pred_2 = (np.sum(y_pred_all_1 * alpha_a, axis=1) >= 0.3).astype(np.int)\n",
    "print('Accuracy: \\n', accuracy_score(y_test, y6b_pred_2))\n",
    "print('f1_Score: \\n', f1_score(y_test, y6b_pred_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exercise 9.6_3 - b\n",
      "\n",
      "Accuracy: \n",
      " 0.6393333333333333\n",
      "f1_Score: \n",
      " 0.6317222600408441\n"
     ]
    }
   ],
   "source": [
    "# Threshold = 0.7\n",
    "print('\\nExercise 9.6_3 - b\\n')\n",
    "y6b_pred_3 = (np.sum(y_pred_all_1 * alpha_a, axis=1) >= 0.7).astype(np.int)\n",
    "print('Accuracy: \\n', accuracy_score(y_test, y6b_pred_3))\n",
    "print('f1_Score: \\n', f1_score(y_test, y6b_pred_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exercise 9.6_4 - b\n",
      "\n",
      "Accuracy: \n",
      " 0.616\n",
      "f1_Score: \n",
      " 0.5589586523736599\n"
     ]
    }
   ],
   "source": [
    "# Threshold = 0.9\n",
    "print('\\nExercise 9.6_4 - b\\n')\n",
    "y6b_pred_4 = (np.sum(y_pred_all_1 * alpha_a, axis=1) >= 0.9).astype(np.int)\n",
    "print('Accuracy: \\n', accuracy_score(y_test, y6b_pred_4))\n",
    "print('f1_Score: \\n', f1_score(y_test, y6b_pred_4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Cuando realizamos un 100 Decision Trees where max_depth=2, ajustando el Threshold,el mejor f1_score lo da cuando lo realizamos con Threshold = 0.1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exercise 9.6_1 - c\n",
      "\n",
      "Accuracy: \n",
      " 0.6273333333333333\n",
      "f1_Score: \n",
      " 0.6459784673844206\n"
     ]
    }
   ],
   "source": [
    "# 100 Logistic Regressions\n",
    "# Threshold = 0.1\n",
    "print('\\nExercise 9.6_1 - c\\n')\n",
    "y6c_pred_1 = (np.sum(y_pred_all_2 * alpha_a, axis=1) >= 0.1).astype(np.int)\n",
    "print('Accuracy: \\n', accuracy_score(y_test, y6c_pred_1))\n",
    "print('f1_Score: \\n', f1_score(y_test, y6c_pred_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exercise 9.6_2 - c\n",
      "\n",
      "Accuracy: \n",
      " 0.6253333333333333\n",
      "f1_Score: \n",
      " 0.6233243967828417\n"
     ]
    }
   ],
   "source": [
    "# Threshold = 0.3\n",
    "print('\\nExercise 9.6_2 - c\\n')\n",
    "y6c_pred_2 = (np.sum(y_pred_all_2 * alpha_a, axis=1) >= 0.3).astype(np.int)\n",
    "print('Accuracy: \\n', accuracy_score(y_test, y6c_pred_2))\n",
    "print('f1_Score: \\n', f1_score(y_test, y6c_pred_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exercise 9.6_3 - c\n",
      "\n",
      "Accuracy: \n",
      " 0.6226666666666667\n",
      "f1_Score: \n",
      " 0.5904486251808972\n"
     ]
    }
   ],
   "source": [
    "# Threshold = 0.7\n",
    "print('\\nExercise 9.6_3 - c\\n')\n",
    "y6c_pred_3 = (np.sum(y_pred_all_2 * alpha_a, axis=1) >= 0.7).astype(np.int)\n",
    "print('Accuracy: \\n', accuracy_score(y_test, y6c_pred_3))\n",
    "print('f1_Score: \\n', f1_score(y_test, y6c_pred_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exercise 9.6_4 - c\n",
      "\n",
      "Accuracy: \n",
      " 0.6453333333333333\n",
      "f1_Score: \n",
      " 0.558032282859339\n"
     ]
    }
   ],
   "source": [
    "# Threshold = 0.9\n",
    "print('\\nExercise 9.6_4 - c\\n')\n",
    "y6c_pred_4 = (np.sum(y_pred_all_2 * alpha_a, axis=1) >= 0.9).astype(np.int)\n",
    "print('Accuracy: \\n', accuracy_score(y_test, y6b_pred_2))\n",
    "print('f1_Score: \\n', f1_score(y_test, y6c_pred_4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando realizamos la regresiÃ³n logistica, el mejor ajuste es Threshold = 0.1con un f1_ score de 65%. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 9.7\n",
    "\n",
    "Estimate a logistic regression using as input the estimated classifiers\n",
    "\n",
    "Modify the probability threshold such that maximizes the F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "# 100 Decision Trees where max_depth=None\n",
    "\n",
    "y_pred_all_ = np.zeros((X_test.shape[0], clf2a.n_estimators))\n",
    "X_train_3a = np.zeros((X_train.shape[0], clf2a.n_estimators))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = np.zeros(clf2a.n_estimators)\n",
    "for i in range(clf2a.n_estimators):\n",
    "   oob_sample = ~clf2a.estimators_samples_[i]\n",
    "   y_pred_ = clf2a.estimators_[i].predict(X_train.values[oob_sample])\n",
    "   errors[i] = accuracy_score(y_pred_, y_train.values[oob_sample])\n",
    "\n",
    "   X_train_3a[:, i] = clf2a.estimators_[i].predict(X_train)\n",
    "   y_pred_all_[:, i] = clf2a.estimators_[i].predict(X_test)\n",
    "\n",
    "alpha_a = (1 - errors) / (1 - errors).sum()\n",
    "\n",
    "lr_a = LogisticRegressionCV(cv=5)\n",
    "lr_a.fit(X_train_3a, y_train)\n",
    "\n",
    "y_pred_7a = lr_a.predict(y_pred_all_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exercise 9.7 - a\n",
      "\n",
      "Accuracy: \n",
      " 0.6353333333333333\n",
      "f1_Score: \n",
      " 0.6336235766912257\n"
     ]
    }
   ],
   "source": [
    "print('\\nExercise 9.7 - a\\n')\n",
    "print('Accuracy: \\n', accuracy_score(y_test, y_pred_7a))\n",
    "print('f1_Score: \\n', f1_score(y_test, y_pred_7a))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
